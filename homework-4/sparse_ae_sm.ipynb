{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T21:03:35.966965Z",
     "start_time": "2018-12-25T21:03:35.328818Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from utils import mnist, plot_graphs, plot_mnist\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T21:03:36.418745Z",
     "start_time": "2018-12-25T21:03:35.967951Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T21:03:36.421555Z",
     "start_time": "2018-12-25T21:03:36.419778Z"
    }
   },
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T21:03:36.446573Z",
     "start_time": "2018-12-25T21:03:36.422899Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,), (0.5,)),\n",
    "           ])\n",
    "train_loader, valid_loader, test_loader = mnist(valid=10000, transform=mnist_transform, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T21:03:36.451729Z",
     "start_time": "2018-12-25T21:03:36.447559Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_size=10):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, latent_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_size=10):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_size, 28*28)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T21:03:36.456993Z",
     "start_time": "2018-12-25T21:03:36.452807Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, latent_size=10, loss_fn=F.mse_loss, lr=1e-4, l2=0.):\n",
    "        super(Net, self).__init__()\n",
    "        self.latent_size = latent_size\n",
    "        self.E = Encoder(latent_size)\n",
    "        self.D = Decoder(latent_size)\n",
    "        self.loss_fn = loss_fn\n",
    "        self._rho_loss = None\n",
    "        self._loss = None\n",
    "        self.optim = optim.Adam(self.parameters(), lr=lr, weight_decay=l2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        h = self.E(x)\n",
    "        self.data_rho = h\n",
    "        out = self.D(h)\n",
    "        return out\n",
    "    \n",
    "    def decode(self, h):\n",
    "        with torch.no_grad():\n",
    "            return self.D(h)\n",
    "    \n",
    "    def rho_loss(self, rho, size_average=True):\n",
    "#         input_ = torch.softmax(self.data_rho, 1)\n",
    "        L = torch.sum(-torch.softmax(self.data_rho, 1))*10000\n",
    "#         target_ = torch.argmax(input_, 1)\n",
    "#         L = F.nll_loss(input_, target_)\n",
    "#         L = torch.abs(self.data_rho)\n",
    "#         L = torch.sum(torch.abs(input_))\n",
    "#         L = self.data_rho*self.data_rho\n",
    "    \n",
    "        if size_average:\n",
    "            self._rho_loss = L.mean()\n",
    "        else:\n",
    "            self._rho_loss = L.sum()\n",
    "        return self._rho_loss\n",
    "    \n",
    "    def loss(self, x, target, **kwargs):\n",
    "        target = target.view(-1, 28*28)\n",
    "        self._loss = self.loss_fn(x, target, **kwargs)\n",
    "        return self._loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T21:03:37.895987Z",
     "start_time": "2018-12-25T21:03:36.458061Z"
    }
   },
   "outputs": [],
   "source": [
    "models = {'16': Net(16).to(device), '32': Net(32).to(device), '64': Net(64).to(device)}\n",
    "# models = {'64': Net(64).to(device)}\n",
    "rho = 0.05\n",
    "train_log = {k: [] for k in models}\n",
    "test_log = {k: [] for k in models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T21:03:37.901346Z",
     "start_time": "2018-12-25T21:03:37.897161Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(epoch, models, log=None):\n",
    "    train_size = len(train_loader.sampler)\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        for model in models.values():\n",
    "            model.optim.zero_grad()\n",
    "            output = model(data.to(device))\n",
    "            rho_loss = model.rho_loss(rho, True)\n",
    "            loss = model.loss(output, data.to(device)) + rho_loss\n",
    "            loss.backward()\n",
    "            model.optim.step()\n",
    "            \n",
    "        if batch_idx % 200 == 0:\n",
    "            line = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLosses '.format(\n",
    "                epoch, batch_idx * len(data), train_size, 100. * batch_idx / len(train_loader))\n",
    "            losses = ' '.join(['{}: {:.6f}'.format(k, m._loss.item()) for k, m in models.items()])\n",
    "            print(line + losses)\n",
    "            \n",
    "    else:\n",
    "        batch_idx += 1\n",
    "        line = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLosses '.format(\n",
    "            epoch, batch_idx * len(data), train_size, 100. * batch_idx / len(train_loader))\n",
    "        losses = ' '.join(['{}: {:.6f}'.format(k, m._loss.item()) for k, m in models.items()])\n",
    "        if log is not None:\n",
    "            for k in models:\n",
    "                log[k].append((models[k]._loss, models[k]._rho_loss))\n",
    "        print(line + losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T21:03:37.910490Z",
     "start_time": "2018-12-25T21:03:37.902775Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_lambda = lambda l: 'loss: {:.4f}'.format(l)\n",
    "rho_lambda = lambda p: 'rho_loss: {}'.format(p)\n",
    "data_rho_lambda = lambda q: 'data_rho: {}'.format(q)\n",
    "line = lambda i, l, p: '{}: '.format(i) + avg_lambda(l) + '\\t' + rho_lambda(p)\n",
    "line_extra = lambda i, l, p, q: '{}: '.format(i) + avg_lambda(l) + '\\t' + rho_lambda(p) + '\\n' + data_rho_lambda(q)\n",
    "    \n",
    "def test(models, loader, log=None):\n",
    "    test_size = len(loader.sampler)\n",
    "\n",
    "\n",
    "    test_loss = {k: 0. for k in models}\n",
    "    rho_loss = {k: 0. for k in models}\n",
    "    with torch.no_grad():\n",
    "        for data, _ in loader:\n",
    "            output = {k: m(data.to(device)) for k, m in models.items()}\n",
    "            for k, m in models.items():\n",
    "                test_loss[k] += m.loss(output[k], data.to(device), reduction='sum').item() # sum up batch loss\n",
    "                rho_loss[k] += m.rho_loss(rho, size_average=False).item()\n",
    "    \n",
    "    for k in models:\n",
    "        test_loss[k] /= (test_size * 784)\n",
    "        rho_loss[k] /= (test_size * models[k].latent_size)\n",
    "        if log is not None:\n",
    "            log[k].append((test_loss[k], rho_loss[k], models[k].data_rho))\n",
    "    \n",
    "    lines = '\\n'.join([line(k, test_loss[k], rho_loss[k]) for k in models]) + '\\n'\n",
    "    report = 'Test set:\\n' + lines        \n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T21:06:59.143288Z",
     "start_time": "2018-12-25T21:03:37.911738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLosses 16: 1.017475 32: 1.048617 64: 1.010983\n",
      "Train Epoch: 1 [10000/50000 (20%)]\tLosses 16: 0.680090 32: 0.341912 64: 0.247856\n",
      "Train Epoch: 1 [20000/50000 (40%)]\tLosses 16: 0.358092 32: 0.258960 64: 0.213812\n",
      "Train Epoch: 1 [30000/50000 (60%)]\tLosses 16: 0.262209 32: 0.225148 64: 0.173567\n",
      "Train Epoch: 1 [40000/50000 (80%)]\tLosses 16: 0.268957 32: 0.231267 64: 0.162054\n",
      "Train Epoch: 1 [50000/50000 (100%)]\tLosses 16: 0.247018 32: 0.206080 64: 0.138117\n",
      "Test set:\n",
      "16: loss: 0.2538\trho_loss: -625.0000037109374\n",
      "32: loss: 0.2111\trho_loss: -312.5000018554687\n",
      "64: loss: 0.1385\trho_loss: -156.24999995117187\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLosses 16: 0.256077 32: 0.213596 64: 0.146986\n",
      "Train Epoch: 2 [10000/50000 (20%)]\tLosses 16: 0.252060 32: 0.202275 64: 0.122994\n",
      "Train Epoch: 2 [20000/50000 (40%)]\tLosses 16: 0.232314 32: 0.175789 64: 0.106689\n",
      "Train Epoch: 2 [30000/50000 (60%)]\tLosses 16: 0.233370 32: 0.172973 64: 0.108219\n",
      "Train Epoch: 2 [40000/50000 (80%)]\tLosses 16: 0.225710 32: 0.161550 64: 0.095262\n",
      "Train Epoch: 2 [50000/50000 (100%)]\tLosses 16: 0.226772 32: 0.159860 64: 0.096171\n",
      "Test set:\n",
      "16: loss: 0.2278\trho_loss: -625.0000017578125\n",
      "32: loss: 0.1611\trho_loss: -312.4999857421875\n",
      "64: loss: 0.0954\trho_loss: -156.24999951171876\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLosses 16: 0.234899 32: 0.167422 64: 0.093257\n",
      "Train Epoch: 3 [10000/50000 (20%)]\tLosses 16: 0.210813 32: 0.148307 64: 0.085632\n",
      "Train Epoch: 3 [20000/50000 (40%)]\tLosses 16: 0.204078 32: 0.135156 64: 0.079914\n",
      "Train Epoch: 3 [30000/50000 (60%)]\tLosses 16: 0.219562 32: 0.146413 64: 0.088027\n",
      "Train Epoch: 3 [40000/50000 (80%)]\tLosses 16: 0.211917 32: 0.146422 64: 0.080600\n",
      "Train Epoch: 3 [50000/50000 (100%)]\tLosses 16: 0.207745 32: 0.137015 64: 0.072234\n",
      "Test set:\n",
      "16: loss: 0.2007\trho_loss: -625.0000068359375\n",
      "32: loss: 0.1336\trho_loss: -312.49999873046875\n",
      "64: loss: 0.0712\trho_loss: -156.2499994140625\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLosses 16: 0.206584 32: 0.133626 64: 0.074676\n",
      "Train Epoch: 4 [10000/50000 (20%)]\tLosses 16: 0.183643 32: 0.115694 64: 0.062218\n",
      "Train Epoch: 4 [20000/50000 (40%)]\tLosses 16: 0.195724 32: 0.129130 64: 0.065919\n",
      "Train Epoch: 4 [30000/50000 (60%)]\tLosses 16: 0.189650 32: 0.127042 64: 0.062705\n",
      "Train Epoch: 4 [40000/50000 (80%)]\tLosses 16: 0.182742 32: 0.119743 64: 0.057371\n",
      "Train Epoch: 4 [50000/50000 (100%)]\tLosses 16: 0.171095 32: 0.108328 64: 0.053231\n",
      "Test set:\n",
      "16: loss: 0.1821\trho_loss: -624.9999978515625\n",
      "32: loss: 0.1180\trho_loss: -312.50000615234376\n",
      "64: loss: 0.0588\trho_loss: -156.250000390625\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLosses 16: 0.172954 32: 0.107981 64: 0.055130\n",
      "Train Epoch: 5 [10000/50000 (20%)]\tLosses 16: 0.173043 32: 0.114472 64: 0.058112\n",
      "Train Epoch: 5 [20000/50000 (40%)]\tLosses 16: 0.177634 32: 0.114626 64: 0.054091\n",
      "Train Epoch: 5 [30000/50000 (60%)]\tLosses 16: 0.160384 32: 0.099833 64: 0.048979\n",
      "Train Epoch: 5 [40000/50000 (80%)]\tLosses 16: 0.168023 32: 0.103898 64: 0.047676\n",
      "Train Epoch: 5 [50000/50000 (100%)]\tLosses 16: 0.174852 32: 0.113524 64: 0.053988\n",
      "Test set:\n",
      "16: loss: 0.1676\trho_loss: -625.0000119140625\n",
      "32: loss: 0.1082\trho_loss: -312.49999248046873\n",
      "64: loss: 0.0506\trho_loss: -156.25000034179686\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLosses 16: 0.163774 32: 0.106945 64: 0.051921\n",
      "Train Epoch: 6 [10000/50000 (20%)]\tLosses 16: 0.152339 32: 0.096292 64: 0.044412\n",
      "Train Epoch: 6 [20000/50000 (40%)]\tLosses 16: 0.181573 32: 0.119496 64: 0.055495\n",
      "Train Epoch: 6 [30000/50000 (60%)]\tLosses 16: 0.155538 32: 0.097615 64: 0.045905\n",
      "Train Epoch: 6 [40000/50000 (80%)]\tLosses 16: 0.165374 32: 0.100082 64: 0.044251\n",
      "Train Epoch: 6 [50000/50000 (100%)]\tLosses 16: 0.153299 32: 0.100644 64: 0.047789\n",
      "Test set:\n",
      "16: loss: 0.1570\trho_loss: -625.000005078125\n",
      "32: loss: 0.1011\trho_loss: -312.49999501953124\n",
      "64: loss: 0.0449\trho_loss: -156.25000092773436\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLosses 16: 0.155914 32: 0.101259 64: 0.043180\n",
      "Train Epoch: 7 [10000/50000 (20%)]\tLosses 16: 0.149067 32: 0.094245 64: 0.041419\n",
      "Train Epoch: 7 [20000/50000 (40%)]\tLosses 16: 0.149626 32: 0.093659 64: 0.038712\n",
      "Train Epoch: 7 [30000/50000 (60%)]\tLosses 16: 0.159322 32: 0.107394 64: 0.048170\n",
      "Train Epoch: 7 [40000/50000 (80%)]\tLosses 16: 0.139970 32: 0.086330 64: 0.037355\n",
      "Train Epoch: 7 [50000/50000 (100%)]\tLosses 16: 0.143956 32: 0.093143 64: 0.039412\n",
      "Test set:\n",
      "16: loss: 0.1488\trho_loss: -625.000005859375\n",
      "32: loss: 0.0954\trho_loss: -312.4999966796875\n",
      "64: loss: 0.0406\trho_loss: -156.25000063476563\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLosses 16: 0.157349 32: 0.099638 64: 0.041973\n",
      "Train Epoch: 8 [10000/50000 (20%)]\tLosses 16: 0.151883 32: 0.098140 64: 0.043037\n",
      "Train Epoch: 8 [20000/50000 (40%)]\tLosses 16: 0.159567 32: 0.104611 64: 0.045343\n",
      "Train Epoch: 8 [30000/50000 (60%)]\tLosses 16: 0.140642 32: 0.088651 64: 0.037256\n",
      "Train Epoch: 8 [40000/50000 (80%)]\tLosses 16: 0.150416 32: 0.094635 64: 0.038285\n",
      "Train Epoch: 8 [50000/50000 (100%)]\tLosses 16: 0.139893 32: 0.091158 64: 0.039112\n",
      "Test set:\n",
      "16: loss: 0.1419\trho_loss: -625.0000080078125\n",
      "32: loss: 0.0907\trho_loss: -312.49999453125\n",
      "64: loss: 0.0374\trho_loss: -156.25000073242188\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLosses 16: 0.148082 32: 0.091875 64: 0.037975\n",
      "Train Epoch: 9 [10000/50000 (20%)]\tLosses 16: 0.123935 32: 0.077712 64: 0.032328\n",
      "Train Epoch: 9 [20000/50000 (40%)]\tLosses 16: 0.127601 32: 0.081426 64: 0.033259\n",
      "Train Epoch: 9 [30000/50000 (60%)]\tLosses 16: 0.139774 32: 0.089714 64: 0.033214\n",
      "Train Epoch: 9 [40000/50000 (80%)]\tLosses 16: 0.139221 32: 0.085054 64: 0.032272\n",
      "Train Epoch: 9 [50000/50000 (100%)]\tLosses 16: 0.142716 32: 0.094189 64: 0.038078\n",
      "Test set:\n",
      "16: loss: 0.1367\trho_loss: -625.000003515625\n",
      "32: loss: 0.0865\trho_loss: -312.4999946289062\n",
      "64: loss: 0.0347\trho_loss: -156.25000024414064\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLosses 16: 0.126371 32: 0.080427 64: 0.034555\n",
      "Train Epoch: 10 [10000/50000 (20%)]\tLosses 16: 0.140059 32: 0.087434 64: 0.034523\n",
      "Train Epoch: 10 [20000/50000 (40%)]\tLosses 16: 0.134406 32: 0.085355 64: 0.034167\n",
      "Train Epoch: 10 [30000/50000 (60%)]\tLosses 16: 0.146049 32: 0.093745 64: 0.040192\n",
      "Train Epoch: 10 [40000/50000 (80%)]\tLosses 16: 0.127713 32: 0.081211 64: 0.030827\n",
      "Train Epoch: 10 [50000/50000 (100%)]\tLosses 16: 0.149387 32: 0.097849 64: 0.036615\n",
      "Test set:\n",
      "16: loss: 0.1327\trho_loss: -625.0000056640625\n",
      "32: loss: 0.0828\trho_loss: -312.4999955078125\n",
      "64: loss: 0.0327\trho_loss: -156.25000107421874\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLosses 16: 0.121286 32: 0.073411 64: 0.028145\n",
      "Train Epoch: 11 [10000/50000 (20%)]\tLosses 16: 0.133576 32: 0.083422 64: 0.032969\n",
      "Train Epoch: 11 [20000/50000 (40%)]\tLosses 16: 0.136759 32: 0.085691 64: 0.033680\n",
      "Train Epoch: 11 [30000/50000 (60%)]\tLosses 16: 0.133749 32: 0.085202 64: 0.032328\n",
      "Train Epoch: 11 [40000/50000 (80%)]\tLosses 16: 0.117719 32: 0.071629 64: 0.027771\n",
      "Train Epoch: 11 [50000/50000 (100%)]\tLosses 16: 0.122451 32: 0.076551 64: 0.030253\n",
      "Test set:\n",
      "16: loss: 0.1290\trho_loss: -625.0000005859375\n",
      "32: loss: 0.0796\trho_loss: -312.4999962890625\n",
      "64: loss: 0.0310\trho_loss: -156.25000102539062\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLosses 16: 0.118855 32: 0.072489 64: 0.029263\n",
      "Train Epoch: 12 [10000/50000 (20%)]\tLosses 16: 0.131170 32: 0.075529 64: 0.027917\n",
      "Train Epoch: 12 [20000/50000 (40%)]\tLosses 16: 0.125053 32: 0.073666 64: 0.029645\n",
      "Train Epoch: 12 [30000/50000 (60%)]\tLosses 16: 0.117078 32: 0.073306 64: 0.027434\n",
      "Train Epoch: 12 [40000/50000 (80%)]\tLosses 16: 0.125925 32: 0.077087 64: 0.029627\n",
      "Train Epoch: 12 [50000/50000 (100%)]\tLosses 16: 0.132346 32: 0.083929 64: 0.031098\n",
      "Test set:\n",
      "16: loss: 0.1260\trho_loss: -625.000003515625\n",
      "32: loss: 0.0769\trho_loss: -312.49999658203126\n",
      "64: loss: 0.0295\trho_loss: -156.249999609375\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLosses 16: 0.126556 32: 0.070672 64: 0.026677\n",
      "Train Epoch: 13 [10000/50000 (20%)]\tLosses 16: 0.119729 32: 0.072278 64: 0.028588\n",
      "Train Epoch: 13 [20000/50000 (40%)]\tLosses 16: 0.131785 32: 0.075224 64: 0.027040\n",
      "Train Epoch: 13 [30000/50000 (60%)]\tLosses 16: 0.114585 32: 0.068715 64: 0.027723\n",
      "Train Epoch: 13 [40000/50000 (80%)]\tLosses 16: 0.122871 32: 0.073082 64: 0.029109\n",
      "Train Epoch: 13 [50000/50000 (100%)]\tLosses 16: 0.125288 32: 0.076587 64: 0.028074\n",
      "Test set:\n",
      "16: loss: 0.1233\trho_loss: -625.0000005859375\n",
      "32: loss: 0.0744\trho_loss: -312.49999521484375\n",
      "64: loss: 0.0282\trho_loss: -156.24999965820314\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLosses 16: 0.128747 32: 0.075915 64: 0.028971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [10000/50000 (20%)]\tLosses 16: 0.117608 32: 0.071094 64: 0.026370\n",
      "Train Epoch: 14 [20000/50000 (40%)]\tLosses 16: 0.123872 32: 0.073458 64: 0.027473\n",
      "Train Epoch: 14 [30000/50000 (60%)]\tLosses 16: 0.126819 32: 0.074187 64: 0.025945\n",
      "Train Epoch: 14 [40000/50000 (80%)]\tLosses 16: 0.125018 32: 0.074124 64: 0.027342\n",
      "Train Epoch: 14 [50000/50000 (100%)]\tLosses 16: 0.130972 32: 0.080965 64: 0.029218\n",
      "Test set:\n",
      "16: loss: 0.1208\trho_loss: -624.9999962890626\n",
      "32: loss: 0.0720\trho_loss: -312.4999958984375\n",
      "64: loss: 0.0271\trho_loss: -156.24999990234375\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLosses 16: 0.119291 32: 0.069289 64: 0.025766\n",
      "Train Epoch: 15 [10000/50000 (20%)]\tLosses 16: 0.113392 32: 0.062835 64: 0.021041\n",
      "Train Epoch: 15 [20000/50000 (40%)]\tLosses 16: 0.123677 32: 0.072286 64: 0.026457\n",
      "Train Epoch: 15 [30000/50000 (60%)]\tLosses 16: 0.107643 32: 0.062590 64: 0.021430\n",
      "Train Epoch: 15 [40000/50000 (80%)]\tLosses 16: 0.104140 32: 0.065702 64: 0.022988\n",
      "Train Epoch: 15 [50000/50000 (100%)]\tLosses 16: 0.121021 32: 0.070043 64: 0.028123\n",
      "Test set:\n",
      "16: loss: 0.1185\trho_loss: -625.000003125\n",
      "32: loss: 0.0699\trho_loss: -312.4999958984375\n",
      "64: loss: 0.0262\trho_loss: -156.25000024414064\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLosses 16: 0.101634 32: 0.056589 64: 0.020098\n",
      "Train Epoch: 16 [10000/50000 (20%)]\tLosses 16: 0.113080 32: 0.064844 64: 0.021211\n",
      "Train Epoch: 16 [20000/50000 (40%)]\tLosses 16: 0.112447 32: 0.067892 64: 0.024853\n",
      "Train Epoch: 16 [30000/50000 (60%)]\tLosses 16: 0.107213 32: 0.063051 64: 0.023560\n",
      "Train Epoch: 16 [40000/50000 (80%)]\tLosses 16: 0.115259 32: 0.065645 64: 0.024603\n",
      "Train Epoch: 16 [50000/50000 (100%)]\tLosses 16: 0.113313 32: 0.068239 64: 0.023745\n",
      "Test set:\n",
      "16: loss: 0.1150\trho_loss: -624.999998828125\n",
      "32: loss: 0.0679\trho_loss: -312.49999404296875\n",
      "64: loss: 0.0254\trho_loss: -156.2499998046875\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLosses 16: 0.118920 32: 0.069155 64: 0.024753\n",
      "Train Epoch: 17 [10000/50000 (20%)]\tLosses 16: 0.107108 32: 0.058221 64: 0.023519\n",
      "Train Epoch: 17 [20000/50000 (40%)]\tLosses 16: 0.113902 32: 0.067975 64: 0.025812\n",
      "Train Epoch: 17 [30000/50000 (60%)]\tLosses 16: 0.124953 32: 0.071384 64: 0.027201\n",
      "Train Epoch: 17 [40000/50000 (80%)]\tLosses 16: 0.106879 32: 0.062594 64: 0.023493\n",
      "Train Epoch: 17 [50000/50000 (100%)]\tLosses 16: 0.116445 32: 0.069172 64: 0.024605\n",
      "Test set:\n",
      "16: loss: 0.1126\trho_loss: -625.00000625\n",
      "32: loss: 0.0660\trho_loss: -312.4999984375\n",
      "64: loss: 0.0246\trho_loss: -156.2499990234375\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLosses 16: 0.103605 32: 0.057989 64: 0.020900\n",
      "Train Epoch: 18 [10000/50000 (20%)]\tLosses 16: 0.115866 32: 0.068424 64: 0.024008\n",
      "Train Epoch: 18 [20000/50000 (40%)]\tLosses 16: 0.106400 32: 0.060717 64: 0.023016\n",
      "Train Epoch: 18 [30000/50000 (60%)]\tLosses 16: 0.123910 32: 0.074148 64: 0.027522\n",
      "Train Epoch: 18 [40000/50000 (80%)]\tLosses 16: 0.114779 32: 0.066372 64: 0.023265\n",
      "Train Epoch: 18 [50000/50000 (100%)]\tLosses 16: 0.112353 32: 0.062800 64: 0.024218\n",
      "Test set:\n",
      "16: loss: 0.1108\trho_loss: -625.0000005859375\n",
      "32: loss: 0.0644\trho_loss: -312.4999969726563\n",
      "64: loss: 0.0240\trho_loss: -156.24999975585936\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLosses 16: 0.102753 32: 0.061678 64: 0.022795\n",
      "Train Epoch: 19 [10000/50000 (20%)]\tLosses 16: 0.106439 32: 0.064461 64: 0.022999\n",
      "Train Epoch: 19 [20000/50000 (40%)]\tLosses 16: 0.110658 32: 0.067895 64: 0.025201\n",
      "Train Epoch: 19 [30000/50000 (60%)]\tLosses 16: 0.110128 32: 0.062018 64: 0.021384\n",
      "Train Epoch: 19 [40000/50000 (80%)]\tLosses 16: 0.105929 32: 0.059302 64: 0.023886\n",
      "Train Epoch: 19 [50000/50000 (100%)]\tLosses 16: 0.100299 32: 0.056703 64: 0.019714\n",
      "Test set:\n",
      "16: loss: 0.1092\trho_loss: -624.99999453125\n",
      "32: loss: 0.0629\trho_loss: -312.4999983398437\n",
      "64: loss: 0.0234\trho_loss: -156.24999951171876\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLosses 16: 0.107898 32: 0.063576 64: 0.023949\n",
      "Train Epoch: 20 [10000/50000 (20%)]\tLosses 16: 0.110166 32: 0.059799 64: 0.022181\n",
      "Train Epoch: 20 [20000/50000 (40%)]\tLosses 16: 0.107740 32: 0.058910 64: 0.022062\n",
      "Train Epoch: 20 [30000/50000 (60%)]\tLosses 16: 0.103712 32: 0.053497 64: 0.019867\n",
      "Train Epoch: 20 [40000/50000 (80%)]\tLosses 16: 0.103321 32: 0.056507 64: 0.020203\n",
      "Train Epoch: 20 [50000/50000 (100%)]\tLosses 16: 0.101626 32: 0.059096 64: 0.021194\n",
      "Test set:\n",
      "16: loss: 0.1075\trho_loss: -624.9999951171875\n",
      "32: loss: 0.0615\trho_loss: -312.499997265625\n",
      "64: loss: 0.0229\trho_loss: -156.24999951171876\n",
      "\n",
      "Train Epoch: 21 [0/50000 (0%)]\tLosses 16: 0.107560 32: 0.061424 64: 0.023217\n",
      "Train Epoch: 21 [10000/50000 (20%)]\tLosses 16: 0.100675 32: 0.056323 64: 0.019974\n",
      "Train Epoch: 21 [20000/50000 (40%)]\tLosses 16: 0.100417 32: 0.059733 64: 0.021716\n",
      "Train Epoch: 21 [30000/50000 (60%)]\tLosses 16: 0.106965 32: 0.061566 64: 0.023010\n",
      "Train Epoch: 21 [40000/50000 (80%)]\tLosses 16: 0.100221 32: 0.059272 64: 0.021866\n",
      "Train Epoch: 21 [50000/50000 (100%)]\tLosses 16: 0.102766 32: 0.057250 64: 0.021837\n",
      "Test set:\n",
      "16: loss: 0.1063\trho_loss: -624.9999857421875\n",
      "32: loss: 0.0603\trho_loss: -312.4999982421875\n",
      "64: loss: 0.0224\trho_loss: -156.24999985351562\n",
      "\n",
      "Train Epoch: 22 [0/50000 (0%)]\tLosses 16: 0.105896 32: 0.059764 64: 0.021752\n",
      "Train Epoch: 22 [10000/50000 (20%)]\tLosses 16: 0.105138 32: 0.056034 64: 0.019789\n",
      "Train Epoch: 22 [20000/50000 (40%)]\tLosses 16: 0.105026 32: 0.061881 64: 0.022798\n",
      "Train Epoch: 22 [30000/50000 (60%)]\tLosses 16: 0.106083 32: 0.058566 64: 0.020831\n",
      "Train Epoch: 22 [40000/50000 (80%)]\tLosses 16: 0.101471 32: 0.060539 64: 0.022120\n",
      "Train Epoch: 22 [50000/50000 (100%)]\tLosses 16: 0.094968 32: 0.054003 64: 0.018098\n",
      "Test set:\n",
      "16: loss: 0.1051\trho_loss: -624.999986328125\n",
      "32: loss: 0.0591\trho_loss: -312.50000224609374\n",
      "64: loss: 0.0219\trho_loss: -156.24999990234375\n",
      "\n",
      "Train Epoch: 23 [0/50000 (0%)]\tLosses 16: 0.111073 32: 0.063677 64: 0.024211\n",
      "Train Epoch: 23 [10000/50000 (20%)]\tLosses 16: 0.092971 32: 0.052610 64: 0.020328\n",
      "Train Epoch: 23 [20000/50000 (40%)]\tLosses 16: 0.111690 32: 0.065750 64: 0.025422\n",
      "Train Epoch: 23 [30000/50000 (60%)]\tLosses 16: 0.098051 32: 0.056634 64: 0.021054\n",
      "Train Epoch: 23 [40000/50000 (80%)]\tLosses 16: 0.102782 32: 0.057509 64: 0.019610\n",
      "Train Epoch: 23 [50000/50000 (100%)]\tLosses 16: 0.088775 32: 0.050724 64: 0.017777\n",
      "Test set:\n",
      "16: loss: 0.1040\trho_loss: -624.9999880859375\n",
      "32: loss: 0.0582\trho_loss: -312.499999609375\n",
      "64: loss: 0.0215\trho_loss: -156.24999946289063\n",
      "\n",
      "Train Epoch: 24 [0/50000 (0%)]\tLosses 16: 0.097144 32: 0.051606 64: 0.018219\n",
      "Train Epoch: 24 [10000/50000 (20%)]\tLosses 16: 0.121851 32: 0.067635 64: 0.024661\n",
      "Train Epoch: 24 [20000/50000 (40%)]\tLosses 16: 0.106432 32: 0.057359 64: 0.020605\n",
      "Train Epoch: 24 [30000/50000 (60%)]\tLosses 16: 0.106231 32: 0.057230 64: 0.021206\n",
      "Train Epoch: 24 [40000/50000 (80%)]\tLosses 16: 0.092293 32: 0.048150 64: 0.017795\n",
      "Train Epoch: 24 [50000/50000 (100%)]\tLosses 16: 0.102631 32: 0.056016 64: 0.021786\n",
      "Test set:\n",
      "16: loss: 0.1031\trho_loss: -624.9999875\n",
      "32: loss: 0.0572\trho_loss: -312.4999995117187\n",
      "64: loss: 0.0212\trho_loss: -156.249999609375\n",
      "\n",
      "Train Epoch: 25 [0/50000 (0%)]\tLosses 16: 0.090462 32: 0.047564 64: 0.020012\n",
      "Train Epoch: 25 [10000/50000 (20%)]\tLosses 16: 0.103959 32: 0.054815 64: 0.020056\n",
      "Train Epoch: 25 [20000/50000 (40%)]\tLosses 16: 0.099937 32: 0.055470 64: 0.021068\n",
      "Train Epoch: 25 [30000/50000 (60%)]\tLosses 16: 0.097554 32: 0.056273 64: 0.020952\n",
      "Train Epoch: 25 [40000/50000 (80%)]\tLosses 16: 0.099017 32: 0.057664 64: 0.021352\n",
      "Train Epoch: 25 [50000/50000 (100%)]\tLosses 16: 0.102681 32: 0.057034 64: 0.020975\n",
      "Test set:\n",
      "16: loss: 0.1023\trho_loss: -624.9999814453125\n",
      "32: loss: 0.0564\trho_loss: -312.5\n",
      "64: loss: 0.0208\trho_loss: -156.24999965820314\n",
      "\n",
      "Train Epoch: 26 [0/50000 (0%)]\tLosses 16: 0.100993 32: 0.050286 64: 0.018158\n",
      "Train Epoch: 26 [10000/50000 (20%)]\tLosses 16: 0.087196 32: 0.047364 64: 0.017215\n",
      "Train Epoch: 26 [20000/50000 (40%)]\tLosses 16: 0.105344 32: 0.059150 64: 0.020509\n",
      "Train Epoch: 26 [30000/50000 (60%)]\tLosses 16: 0.090627 32: 0.050941 64: 0.020506\n",
      "Train Epoch: 26 [40000/50000 (80%)]\tLosses 16: 0.099862 32: 0.053472 64: 0.020147\n",
      "Train Epoch: 26 [50000/50000 (100%)]\tLosses 16: 0.094901 32: 0.051255 64: 0.019176\n",
      "Test set:\n",
      "16: loss: 0.1013\trho_loss: -624.9999884765625\n",
      "32: loss: 0.0556\trho_loss: -312.4999978515625\n",
      "64: loss: 0.0204\trho_loss: -156.24999970703124\n",
      "\n",
      "Train Epoch: 27 [0/50000 (0%)]\tLosses 16: 0.110481 32: 0.063475 64: 0.024284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 27 [10000/50000 (20%)]\tLosses 16: 0.102379 32: 0.053490 64: 0.019158\n",
      "Train Epoch: 27 [20000/50000 (40%)]\tLosses 16: 0.106523 32: 0.058301 64: 0.019915\n",
      "Train Epoch: 27 [30000/50000 (60%)]\tLosses 16: 0.096258 32: 0.049712 64: 0.018914\n",
      "Train Epoch: 27 [40000/50000 (80%)]\tLosses 16: 0.104410 32: 0.058430 64: 0.021656\n",
      "Train Epoch: 27 [50000/50000 (100%)]\tLosses 16: 0.097285 32: 0.051430 64: 0.017981\n",
      "Test set:\n",
      "16: loss: 0.1005\trho_loss: -624.9999947265625\n",
      "32: loss: 0.0547\trho_loss: -312.499997265625\n",
      "64: loss: 0.0201\trho_loss: -156.24999975585936\n",
      "\n",
      "Train Epoch: 28 [0/50000 (0%)]\tLosses 16: 0.078182 32: 0.042826 64: 0.015854\n",
      "Train Epoch: 28 [10000/50000 (20%)]\tLosses 16: 0.102701 32: 0.057355 64: 0.020795\n",
      "Train Epoch: 28 [20000/50000 (40%)]\tLosses 16: 0.104345 32: 0.055734 64: 0.020987\n",
      "Train Epoch: 28 [30000/50000 (60%)]\tLosses 16: 0.101297 32: 0.051297 64: 0.018441\n",
      "Train Epoch: 28 [40000/50000 (80%)]\tLosses 16: 0.090094 32: 0.054626 64: 0.020635\n",
      "Train Epoch: 28 [50000/50000 (100%)]\tLosses 16: 0.105467 32: 0.052059 64: 0.019582\n",
      "Test set:\n",
      "16: loss: 0.0998\trho_loss: -624.9999921875\n",
      "32: loss: 0.0540\trho_loss: -312.50000107421874\n",
      "64: loss: 0.0199\trho_loss: -156.24999956054688\n",
      "\n",
      "Train Epoch: 29 [0/50000 (0%)]\tLosses 16: 0.095425 32: 0.051550 64: 0.018347\n",
      "Train Epoch: 29 [10000/50000 (20%)]\tLosses 16: 0.106710 32: 0.063639 64: 0.023107\n",
      "Train Epoch: 29 [20000/50000 (40%)]\tLosses 16: 0.110435 32: 0.058160 64: 0.021381\n",
      "Train Epoch: 29 [30000/50000 (60%)]\tLosses 16: 0.092087 32: 0.050457 64: 0.015753\n",
      "Train Epoch: 29 [40000/50000 (80%)]\tLosses 16: 0.103385 32: 0.054442 64: 0.020015\n",
      "Train Epoch: 29 [50000/50000 (100%)]\tLosses 16: 0.095097 32: 0.051238 64: 0.017264\n",
      "Test set:\n",
      "16: loss: 0.0991\trho_loss: -624.999989453125\n",
      "32: loss: 0.0534\trho_loss: -312.5000009765625\n",
      "64: loss: 0.0196\trho_loss: -156.25\n",
      "\n",
      "Train Epoch: 30 [0/50000 (0%)]\tLosses 16: 0.107366 32: 0.053955 64: 0.019940\n",
      "Train Epoch: 30 [10000/50000 (20%)]\tLosses 16: 0.094256 32: 0.051800 64: 0.018465\n",
      "Train Epoch: 30 [20000/50000 (40%)]\tLosses 16: 0.093824 32: 0.050263 64: 0.018378\n",
      "Train Epoch: 30 [30000/50000 (60%)]\tLosses 16: 0.098256 32: 0.049011 64: 0.016981\n",
      "Train Epoch: 30 [40000/50000 (80%)]\tLosses 16: 0.101076 32: 0.053331 64: 0.018728\n",
      "Train Epoch: 30 [50000/50000 (100%)]\tLosses 16: 0.095003 32: 0.051141 64: 0.018426\n",
      "Test set:\n",
      "16: loss: 0.0983\trho_loss: -624.9999927734375\n",
      "32: loss: 0.0528\trho_loss: -312.5\n",
      "64: loss: 0.0194\trho_loss: -156.24999975585936\n",
      "\n",
      "Train Epoch: 31 [0/50000 (0%)]\tLosses 16: 0.094688 32: 0.050634 64: 0.019088\n",
      "Train Epoch: 31 [10000/50000 (20%)]\tLosses 16: 0.097715 32: 0.055523 64: 0.019802\n",
      "Train Epoch: 31 [20000/50000 (40%)]\tLosses 16: 0.103763 32: 0.058312 64: 0.019720\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5729fa1e0e9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-20692956359f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, models, log)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mrho_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrho_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrho_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/alex/Data/alex/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-4d5deda5746a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_rho\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/alex/Data/alex/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-837a9144757f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/alex/Data/alex/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/alex/Data/alex/anaconda3/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/alex/Data/alex/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 101):\n",
    "    for model in models.values():\n",
    "        model.train()\n",
    "    train(epoch, models, train_log)\n",
    "    for model in models.values():\n",
    "        model.eval()\n",
    "    test(models, valid_loader, test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T21:06:59.144145Z",
     "start_time": "2018-12-25T21:03:35.355Z"
    }
   },
   "outputs": [],
   "source": [
    "test_log['64']\n",
    "losses = np.array([[it[0],it[1]] for it in test_log['64']])\n",
    "N = losses.shape[0]\n",
    "plt.figure(1), plt.plot(range(N), losses[:,0])\n",
    "plt.figure(2), plt.plot(range(N), losses[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T21:06:59.145150Z",
     "start_time": "2018-12-25T21:03:35.357Z"
    }
   },
   "outputs": [],
   "source": [
    "mod = '64'\n",
    "mod_ = int(mod)\n",
    "data, _ = next(iter(test_loader))\n",
    "output = models[mod](data.to(device))\n",
    "to_plot = output.view(-1, 1, 28, 28).clamp(0, 1).data.cpu().numpy()\n",
    "decoded = models[mod].decode(torch.eye(mod_).to(device))\n",
    "dec_to_plot = ((decoded.view(-1, 1, 28, 28)+1)*0.5).clamp(0, 1).data.cpu().numpy()\n",
    "decoded_neg = models[mod].decode(-torch.eye(mod_).to(device))\n",
    "dec_neg_to_plot = ((decoded_neg.view(-1, 1, 28, 28)+1)*0.5).clamp(0, 1).data.cpu().numpy()\n",
    "with torch.no_grad():\n",
    "    encoded = models[mod].E(data.view(-1, 28*28).to(device))\n",
    "    print((torch.abs(encoded) > 0.2).sum(1))\n",
    "    encoded[torch.abs(encoded) < 0.2] = 0.\n",
    "    decoded_f = models[mod].decode(encoded)\n",
    "    f_to_plot = ((decoded_f.view(-1, 1, 28, 28)+1)*0.5).clamp(0, 1).data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T21:06:59.145898Z",
     "start_time": "2018-12-25T21:03:35.359Z"
    }
   },
   "outputs": [],
   "source": [
    "mod = '64'\n",
    "mod_ = int(mod)\n",
    "data, _ = next(iter(test_loader))\n",
    "with torch.no_grad():\n",
    "    encoded = models[mod].E(data.view(-1, 28*28).to(device))\n",
    "#     print(encoded.size())\n",
    "    plt.figure(1), sns.barplot(np.arange(mod_), encoded.mean(0), palette=\"rocket\")\n",
    "    plt.figure(2), sns.distplot(encoded.reshape([-1,1]).cpu().numpy())\n",
    "#     plt.figure(3), sns.violinplot(encoded.reshape([-1,1]).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T21:06:59.146765Z",
     "start_time": "2018-12-25T21:03:35.360Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_mnist(data.data.numpy(), (5, 10))\n",
    "plot_mnist(to_plot, (5, 10))\n",
    "# plot_mnist(f_to_plot, (5, 10))\n",
    "plot_mnist(dec_to_plot, (8, 8))\n",
    "plot_mnist(dec_neg_to_plot, (8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
